{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8f4fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning in Python\n",
    "#Python data types\n",
    "# str\n",
    "# int\n",
    "# float\n",
    "# bool\n",
    "# datetime\n",
    "# category\n",
    "\n",
    "# Data type Example\n",
    "# Textdata Firstname,lastname,address...\n",
    "# Integers #Subscribers,#productssold...\n",
    "# Decimals Temperature,$exchangerates...\n",
    "# Binary Ismarried,newcustomer,yes/no,...\n",
    "# Dates Orderdates,shipdates...\n",
    "# Categories Marriagestatus,gender...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6de2165e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalesOrderID</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12345</td>\n",
       "      <td>232432$</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34324</td>\n",
       "      <td>34532$</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalesOrderID  Revenue  Quantity\n",
       "0         12345  232432$        12\n",
       "1         34324   34532$         2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Import CSV file and output header\n",
    "sales = pd.read_csv('datasets/sales.csv')\n",
    "sales.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00c26ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalesOrderID     int64\n",
       "Revenue         object\n",
       "Quantity         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data types of columns\n",
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "833d1f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   SalesOrderID  2 non-null      int64 \n",
      " 1   Revenue       2 non-null      object\n",
      " 2   Quantity      2 non-null      int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 176.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# Get DataFrame information\n",
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ddaa224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'232432$34532$'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print sum of all Revenue column\n",
    "sales['Revenue'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a08729a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove $ from Revenue column\n",
    "sales['Revenue'] = sales['Revenue'].str.strip('$')\n",
    "sales['Revenue'] = sales['Revenue'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d13e1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that Revenue is now an integer\n",
    "assert sales['Revenue'].dtype == 'int'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4973ee40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266964"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print sum of all Revenue column\n",
    "sales['Revenue'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7260b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asset statement can use for data healhcheck \n",
    "assert 1+1 == 2\n",
    "# This will pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb44929f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1188/3089963390.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 1+1 == 3\n",
    "# This will fail with AssertionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8015e149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marriage_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        marriage_status\n",
       "count                 8\n",
       "unique                3\n",
       "top                   3\n",
       "freq                  4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/marriage_status.csv')\n",
    "# Numeric or categorical?\n",
    "# You can change numberic value type to category and then descripe will treat it like categorical data\n",
    "df['marriage_status'].describe()\n",
    "\n",
    "# Convert to categorical\n",
    "df[\"marriage_status\"] = df[\"marriage_status\"].astype('category')\n",
    "df.describe()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32f1135d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>avg_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frozen 2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shrek</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shrek</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shrek</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      movie_name  avg_rating\n",
       "0  The Godfather           3\n",
       "1       Frozen 2           4\n",
       "2          Shrek           5\n",
       "3          Shrek           5\n",
       "4          Shrek           5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('datasets/movies.csv')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f46f3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Average rating of movies (1-5)')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(movies['avg_rating'])\n",
    "plt.title('Average rating of movies (1-5)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858f7982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import date time\n",
    "import datetime as dt\n",
    "today_date = dt.date.today()\n",
    "user_signups[user_signups['subscription_date'] > dt.date.today()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d972120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25760 entries, 0 to 25759\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Unnamed: 0       25760 non-null  int64 \n",
      " 1   duration         25760 non-null  object\n",
      " 2   station_A_id     25760 non-null  int64 \n",
      " 3   station_A_name   25760 non-null  object\n",
      " 4   station_B_id     25760 non-null  int64 \n",
      " 5   station_B_name   25760 non-null  object\n",
      " 6   bike_id          25760 non-null  int64 \n",
      " 7   user_type        25760 non-null  int64 \n",
      " 8   user_birth_year  25760 non-null  int64 \n",
      " 9   user_gender      25760 non-null  object\n",
      "dtypes: int64(6), object(4)\n",
      "memory usage: 2.0+ MB\n",
      "None\n",
      "count    25760.000000\n",
      "mean         2.008385\n",
      "std          0.704541\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          2.000000\n",
      "75%          3.000000\n",
      "max          3.000000\n",
      "Name: user_type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ride_sharing = pd.read_csv('datasets/ride_sharing_new.csv')\n",
    "# Print the information of ride_sharing\n",
    "print(ride_sharing.info())\n",
    "\n",
    "# Print summary statistics of user_type column\n",
    "print(ride_sharing['user_type'].describe())\n",
    "\n",
    "# The user_type column contains information on whether a user is taking a free ride and takes on the following values:\n",
    "# 1 for free riders.# 2 for pay per ride.# 3 for monthly subscribers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8b5c29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     25760\n",
      "unique        3\n",
      "top           2\n",
      "freq      12972\n",
      "Name: user_type_cat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert user_type from integer to category\n",
    "ride_sharing['user_type_cat'] = ride_sharing['user_type'].astype('category')\n",
    "\n",
    "# Write an assert statement confirming the change\n",
    "assert ride_sharing['user_type_cat'].dtype == 'category'\n",
    "\n",
    "# Print new summary statistics \n",
    "print(ride_sharing['user_type_cat'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a8254b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         duration duration_trim  duration_time\n",
      "0      12 minutes           12              12\n",
      "1      24 minutes           24              24\n",
      "2       8 minutes            8               8\n",
      "3       4 minutes            4               4\n",
      "4      11 minutes           11              11\n",
      "...           ...           ...            ...\n",
      "25755  11 minutes           11              11\n",
      "25756  10 minutes           10              10\n",
      "25757  14 minutes           14              14\n",
      "25758  14 minutes           14              14\n",
      "25759  29 minutes           29              29\n",
      "\n",
      "[25760 rows x 3 columns]\n",
      "11.389052795031056\n"
     ]
    }
   ],
   "source": [
    "# Strip duration of minutes\n",
    "ride_sharing['duration_trim'] = ride_sharing['duration'].str.strip(\"minutes\")\n",
    "\n",
    "# Convert duration to integer\n",
    "ride_sharing['duration_time'] = ride_sharing['duration_trim'].astype('int')\n",
    "\n",
    "# Write an assert statement making sure of conversion\n",
    "assert ride_sharing['duration_time'].dtype == 'int'\n",
    "\n",
    "# Print formed columns and calculate average ride duration \n",
    "print(ride_sharing[['duration','duration_trim','duration_time']])\n",
    "print(ride_sharing['duration_time'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16cf9c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-23\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "print(dt.date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8bf3650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>avg_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [movie_name, avg_rating]\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output Movies with rating > 5\n",
    "movies[movies['avg_rating'] > 25]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98002564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to deal with missing data\n",
    "#1 Dropping data \n",
    "\n",
    "# Drop values using filtering\n",
    "movies = movies[movies['avg_rating'] <= 5]\n",
    "# Drop values using .drop()\n",
    "movies.drop(movies[movies['avg_rating'] <= 5].index, inplace = True)\n",
    "# Check with assert statement\n",
    "movies['avg_rating'].max() <= 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277375ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#2 Seting custom minimums and maximums\n",
    "# Convert avg_rating > 5 to 5\n",
    "movies.loc[movies['avg_rating'] > 5, 'avg_rating'] = 5\n",
    "\n",
    "#3 Treat as missing and impute\n",
    "\n",
    "#4 Setting custom value depending on business assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c25b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tire_sizes to integer\n",
    "ride_sharing['tire_sizes'] = ride_sharing['tire_sizes'].astype('int')\n",
    "\n",
    "# Set all values above 27 to 27\n",
    "ride_sharing.loc[ride_sharing['tire_sizes'] > 27, 'tire_sizes'] = 27\n",
    "\n",
    "# Reconvert tire_sizes back to categorical\n",
    "ride_sharing['tire_sizes'] = ride_sharing['tire_sizes'].astype('category')\n",
    "\n",
    "# Print tire size description\n",
    "print(ride_sharing['tire_sizes'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aea25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ride_date to date\n",
    "ride_sharing['ride_dt'] = pd.to_datetime(ride_sharing['ride_date']).dt.date\n",
    "\n",
    "# Save today's date\n",
    "today = dt.date.today()\n",
    "\n",
    "# Set all in the future to today's date\n",
    "ride_sharing.loc[ride_sharing['ride_dt'] > today, 'ride_dt'] = today\n",
    "\n",
    "# Print maximum of ride_dt column\n",
    "print(ride_sharing['ride_dt'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e231ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniqueness constraints\n",
    "\n",
    "# How to fix Duplicate value\n",
    "# Can be data entry error. and value can be different in only 1 column\n",
    "# How to find duplicate value\n",
    "#-- duplicates = df.duplicated()\n",
    "#-- df[duplicates]\n",
    "\n",
    "# .duplicated() method to find duplicates\n",
    "# subset: List of column name to check for duplication\n",
    "# keep: Whether to keep first('first'),last('last') or all (False) duplicate values.\n",
    "#-- Column name to check for duplication\n",
    "#-- column_names = ['col_first','col_second']\n",
    "#-- duplicates = df.duplicated(subset = column_names,keep = False)\n",
    "#-- Output duplicate values\n",
    "#-- df[duplicaes].sort_values(by = 'col_name')\n",
    "\n",
    "# .drop_duplicates() method to drop duplicates value\n",
    "# subset: List of column name to check for duplication\n",
    "# keep: Whether to keep first('first'),last('last') or all (False) duplicate values.\n",
    "# inplace: Drop duplicated rows directly inside DataFrame without creating new object(True)\n",
    "#-- df.drop_duplicates(inplace = True)\n",
    "\n",
    "# Statistical measure to handle duplicate data\n",
    "# .groupby() and .agg()\n",
    "# Group by column names and produce statistical summaries\n",
    "# column_names = ['first_name','last_name','address']\n",
    "# summaries = {'height': 'max', 'weight': 'mean'}\n",
    "# height_weight = height_weight.groupby(by = column_names).agg(summaries).reset_index()\n",
    "# # Make sure aggregation is done\n",
    "# duplicates = height_weight.duplicated(subset = column_names, keep = False)\n",
    "# height_weight[duplicates].sort_values(by = 'first_name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5242316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membership constraints\n",
    "\n",
    "# remove incosistencies based on category data\n",
    "# Anti Joins # Left Anti Join # What is in A and not in B\n",
    "# Inner Joins # What is in both A and B\n",
    "\n",
    "# Find difference\n",
    "inconsistent_categories = set(df['column']).difference(categories['column'])\n",
    "inconsistent_rows   = df['column'].isin(new_set)\n",
    "inconsistent_data = df[inconsistent_rows]\n",
    "consistent_data = df[~inconsistent_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56d0bb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>day</th>\n",
       "      <th>airline</th>\n",
       "      <th>destination</th>\n",
       "      <th>dest_region</th>\n",
       "      <th>dest_size</th>\n",
       "      <th>boarding_area</th>\n",
       "      <th>dept_time</th>\n",
       "      <th>wait_min</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>safety</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1351</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>UNITED INTL</td>\n",
       "      <td>KANSAI</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 91-102</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>373</td>\n",
       "      <td>Friday</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>SAN JOSE DEL CABO</td>\n",
       "      <td>Canada/Mexico</td>\n",
       "      <td>Small</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2820</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>DELTA</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 40-48</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1157</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 20-39</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>190.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2992</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>MIAMI</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>559.0</td>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    id        day      airline        destination    dest_region  \\\n",
       "0           0  1351    Tuesday  UNITED INTL             KANSAI           Asia   \n",
       "1           1   373     Friday       ALASKA  SAN JOSE DEL CABO  Canada/Mexico   \n",
       "2           2  2820   Thursday        DELTA        LOS ANGELES        West US   \n",
       "3           3  1157    Tuesday    SOUTHWEST        LOS ANGELES        West US   \n",
       "4           4  2992  Wednesday     AMERICAN              MIAMI        East US   \n",
       "\n",
       "  dest_size boarding_area   dept_time  wait_min     cleanliness  \\\n",
       "0       Hub  Gates 91-102  2018-12-31     115.0           Clean   \n",
       "1     Small   Gates 50-59  2018-12-31     135.0           Clean   \n",
       "2       Hub   Gates 40-48  2018-12-31      70.0         Average   \n",
       "3       Hub   Gates 20-39  2018-12-31     190.0           Clean   \n",
       "4       Hub   Gates 50-59  2018-12-31     559.0  Somewhat clean   \n",
       "\n",
       "          safety        satisfaction  \n",
       "0        Neutral      Very satisfied  \n",
       "1      Very safe      Very satisfied  \n",
       "2  Somewhat safe             Neutral  \n",
       "3      Very safe  Somewhat satsified  \n",
       "4      Very safe  Somewhat satsified  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "airlines = pd.read_csv('datasets/airlines_final.csv')\n",
    "airlines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8507829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cleanliness           safety          satisfaction\n",
      "0           Clean          Neutral        Very satisfied\n",
      "1         Average        Very safe               Neutral\n",
      "2  Somewhat clean    Somewhat safe    Somewhat satisfied\n",
      "3  Somewhat dirty      Very unsafe  Somewhat unsatisfied\n",
      "4           Dirty  Somewhat unsafe      Very unsatisfied\n"
     ]
    }
   ],
   "source": [
    "categories = pd.read_csv('datasets/airline_categories.csv')\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6339366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanliness:  ['Clean' 'Average' 'Somewhat clean' 'Somewhat dirty' 'Dirty'] \n",
      "\n",
      "Safety:  ['Neutral' 'Very safe' 'Somewhat safe' 'Very unsafe' 'Somewhat unsafe'] \n",
      "\n",
      "Satisfaction:  ['Very satisfied' 'Neutral' 'Somewhat satsified' 'Somewhat unsatisfied'\n",
      " 'Very unsatisfied'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print unique values of survey columns in airlines\n",
    "print('Cleanliness: ', airlines['cleanliness'].unique(), \"\\n\")\n",
    "print('Safety: ', airlines['safety'].unique(), \"\\n\")\n",
    "print('Satisfaction: ', airlines['satisfaction'].unique(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3e40ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables\n",
    "\n",
    "#Value consistency due to capitalization problem\n",
    "# marriage_status = demographics['marriage_status']\n",
    "# marriage_status.value_counts() # for series data\n",
    "# marriage_status.groupby('marriage_status').count() # For dataframe\n",
    "# can be fix using .str.upper() or .str.lower()\n",
    "\n",
    "# Trailing spaces\n",
    "# can be fix by str.strip()\n",
    "\n",
    "# Create categories out of data\n",
    "# pandas.qcut(df)\n",
    "# pandas.cut()\n",
    "# .replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a12b73cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
      " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
      " 'Australia/New Zealand' 'middle east']\n",
      "['Hub' 'Small' '    Hub' 'Medium' 'Large' 'Hub     ' '    Small'\n",
      " 'Medium     ' '    Medium' 'Small     ' '    Large' 'Large     ']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airlines = pd.read_csv('datasets/airlines_final.csv')\n",
    "\n",
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f52901c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asia' 'canada/mexico' 'west us' 'east us' 'midwest us' 'middle east'\n",
      " 'europe' 'central/south america' 'australia/new zealand']\n",
      "['Hub' 'Small' 'Medium' 'Large']\n"
     ]
    }
   ],
   "source": [
    "# Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "airlines['dest_region'] = airlines['dest_region'].str.lower()\n",
    "airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})\n",
    "# Remove white spaces from `dest_size`\n",
    "airlines['dest_size'] = airlines['dest_size'].str.strip()\n",
    "\n",
    "# Verify changes have been effected\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "41d04863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['medium', 'long', 'short']\n",
      "Categories (3, object): ['short' < 'medium' < 'long']\n",
      "['weekday' 'weekend']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Create ranges for categories\n",
    "label_ranges = [0, 60, 180, np.inf]\n",
    "label_names = ['short', 'medium', 'long']\n",
    "\n",
    "# Create wait_type column\n",
    "airlines['wait_type'] = pd.cut(airlines['wait_min'], bins = label_ranges, \n",
    "                                labels = label_names)\n",
    "\n",
    "# Create mappings and replace\n",
    "mappings = {'Monday':'weekday', 'Tuesday':'weekday', 'Wednesday': 'weekday', \n",
    "            'Thursday': 'weekday', 'Friday': 'weekday', \n",
    "            'Saturday': 'weekend', 'Sunday': 'weekend'}\n",
    "\n",
    "airlines['day_week'] = airlines['day'].replace(mappings)\n",
    "\n",
    "print(airlines['wait_type'].unique())\n",
    "print(airlines['day_week'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36ad4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning text data\n",
    "\n",
    "# Data inconsistency with typo and length\n",
    "\n",
    "# # Replace \"Dr.\" with empty string \"\"\n",
    "# airlines['full_name'] = airlines['full_name'].str.replace(\"Dr.\",\"\")\n",
    "\n",
    "# # Replace \"Mr.\" with empty string \"\"\n",
    "# airlines['full_name'] = airlines['full_name'].str.replace(\"Mr.\",\"\")\n",
    "\n",
    "# # Replace \"Miss\" with empty string \"\"\n",
    "# airlines['full_name'] = airlines['full_name'].str.replace(\"Miss\",\"\")\n",
    "\n",
    "# # Replace \"Ms.\" with empty string \"\"\n",
    "# airlines['full_name'] = airlines['full_name'].str.replace(\"Ms.\",\"\")\n",
    "\n",
    "# # Assert that full_name has no honorifics\n",
    "# assert airlines['full_name'].str.contains('Ms.|Mr.|Miss|Dr.').any() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aac6650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store length of each row in survey_response column\n",
    "# resp_length = airlines['survey_response'].str.len()\n",
    "\n",
    "# # Find rows in airlines where resp_length > 40\n",
    "# airlines_survey = airlines[resp_length > 40]\n",
    "\n",
    "# # Assert minimum survey_response length is > 40\n",
    "# assert airlines_survey['survey_response'].str.len().min() > 40\n",
    "\n",
    "# # Print new survey_response column\n",
    "# print(airlines_survey['survey_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniformity\n",
    "# problem of different scale of data. ex celsius an fahrenheit  , ex - different date format\n",
    "# can check by using plt.scatter\n",
    "# datetime can be format pandas.to_datetime(df['col'],\n",
    "                                                # Attempt to infer format of each date\n",
    "                                                infer_datetime_format=True,\n",
    "                                                #Return NA for rows where conversion failed\n",
    "                                                errors='coerce')\n",
    "    \n",
    "#    df['col'].dt.strftime(\"%d-%m%Y\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bc8f24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cust_id</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>Age</th>\n",
       "      <th>acct_amount</th>\n",
       "      <th>inv_amount</th>\n",
       "      <th>fund_A</th>\n",
       "      <th>fund_B</th>\n",
       "      <th>fund_C</th>\n",
       "      <th>fund_D</th>\n",
       "      <th>account_opened</th>\n",
       "      <th>last_transaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>870A9282</td>\n",
       "      <td>1962-06-09</td>\n",
       "      <td>58</td>\n",
       "      <td>63523.31</td>\n",
       "      <td>51295</td>\n",
       "      <td>30105.0</td>\n",
       "      <td>4138.0</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>15632.0</td>\n",
       "      <td>21-14-17</td>\n",
       "      <td>22-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>870A9281</td>\n",
       "      <td>1962-06-09</td>\n",
       "      <td>58</td>\n",
       "      <td>63523.31</td>\n",
       "      <td>51295</td>\n",
       "      <td>30105.0</td>\n",
       "      <td>4138.0</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>15632.0</td>\n",
       "      <td>02-09-18</td>\n",
       "      <td>22-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>166B05B0</td>\n",
       "      <td>1962-12-16</td>\n",
       "      <td>58</td>\n",
       "      <td>38175.46</td>\n",
       "      <td>15050</td>\n",
       "      <td>4995.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td>6696.0</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>28-02-19</td>\n",
       "      <td>31-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>BFC13E88</td>\n",
       "      <td>1990-09-12</td>\n",
       "      <td>34</td>\n",
       "      <td>59863.77</td>\n",
       "      <td>24567</td>\n",
       "      <td>10323.0</td>\n",
       "      <td>4590.0</td>\n",
       "      <td>8469.0</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>25-04-18</td>\n",
       "      <td>02-04-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>F2158F66</td>\n",
       "      <td>1985-11-03</td>\n",
       "      <td>35</td>\n",
       "      <td>84132.10</td>\n",
       "      <td>23712</td>\n",
       "      <td>3908.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>6482.0</td>\n",
       "      <td>12830.0</td>\n",
       "      <td>07-11-17</td>\n",
       "      <td>08-11-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   cust_id  birth_date  Age  acct_amount  inv_amount   fund_A  \\\n",
       "0           0  870A9282  1962-06-09   58     63523.31       51295  30105.0   \n",
       "1           0  870A9281  1962-06-09   58     63523.31       51295  30105.0   \n",
       "2           1  166B05B0  1962-12-16   58     38175.46       15050   4995.0   \n",
       "3           2  BFC13E88  1990-09-12   34     59863.77       24567  10323.0   \n",
       "4           3  F2158F66  1985-11-03   35     84132.10       23712   3908.0   \n",
       "\n",
       "   fund_B  fund_C   fund_D account_opened last_transaction  \n",
       "0  4138.0  1420.0  15632.0       21-14-17         22-02-19  \n",
       "1  4138.0  1420.0  15632.0       02-09-18         22-02-19  \n",
       "2   938.0  6696.0   2421.0       28-02-19         31-10-18  \n",
       "3  4590.0  8469.0   1185.0       25-04-18         02-04-18  \n",
       "4   492.0  6482.0  12830.0       07-11-17         08-11-18  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "banking = pd.read_csv('datasets/banking_dirty.csv')\n",
    "\n",
    "banking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2435847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find values of acct_cur that are equal to 'euro'\n",
    "# acct_eu = banking['acct_cur'] == 'euro'\n",
    "\n",
    "# # Convert acct_amount where it is in euro to dollars\n",
    "# banking.loc[acct_eu,'acct_amount'] = banking.loc[acct_eu,'acct_amount'] * 1.1\n",
    "\n",
    "# # Unify acct_cur column by changing 'euro' values to 'dollar'\n",
    "# banking.loc[acct_eu,'acct_cur'] = 'dollar'\n",
    "\n",
    "# # Assert that only dollar currency remains\n",
    "# assert banking['acct_cur'].unique() == 'dollar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92af5133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    21-14-17\n",
      "1    02-09-18\n",
      "2    28-02-19\n",
      "3    25-04-18\n",
      "4    07-11-17\n",
      "Name: account_opened, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print the header of account_opened\n",
    "print(banking['account_opened'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c361565",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "month must be in 1..12: 21-14-17",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_naive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36m_build_naive\u001b[1;34m(self, res, default)\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m         \u001b[0mnaive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: month must be in 1..12",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDEFAULTPARSER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    650\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m             \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParserError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\": %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimestr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: month must be in 1..12: 21-14-17",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: invalid string coercion to datetime",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_naive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36m_build_naive\u001b[1;34m(self, res, default)\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m         \u001b[0mnaive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: month must be in 1..12",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15632/191257668.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbanking\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'account_opened'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m    885\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 887\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    888\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mABCDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMutableMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[0mutc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtz\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"utc\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m     result, tz_parsed = objects_to_datetime64ns(\n\u001b[0m\u001b[0;32m    402\u001b[0m         \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[0mdayfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2191\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz_parsed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2193\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2195\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtz_parsed\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2173\u001b[0m     \u001b[0morder\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"F\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"C\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"F\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"C\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2174\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2175\u001b[1;33m         result, tz_parsed = tslib.array_to_datetime(\n\u001b[0m\u001b[0;32m   2176\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2177\u001b[0m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib._array_to_datetime_object\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib._array_to_datetime_object\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparserinfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDEFAULTPARSER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_naive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m             \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParserError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\": %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimestr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignoretz\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\software\\anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: month must be in 1..12: 21-14-17"
     ]
    }
   ],
   "source": [
    "pd.to_datetime(banking['account_opened'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "180168e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    21-14-17\n",
      "1    02-09-18\n",
      "2    28-02-19\n",
      "3    25-04-18\n",
      "4    07-11-17\n",
      "Name: account_opened, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print the header of account_opened\n",
    "print(banking['account_opened'].head())\n",
    "\n",
    "# Convert account_opened to datetime\n",
    "banking['account_opened'] = pd.to_datetime(banking['account_opened'],\n",
    "                                           # Infer datetime format\n",
    "                                           infer_datetime_format = True,\n",
    "                                           # Return missing value for error\n",
    "                                           errors = 'coerce') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74aecdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          NaT\n",
      "1   2018-02-09\n",
      "2   2019-02-28\n",
      "3   2018-04-25\n",
      "4   2017-07-11\n",
      "Name: account_opened, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(banking['account_opened'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fab09f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       NaN\n",
      "1      2018\n",
      "2      2019\n",
      "3      2018\n",
      "4      2017\n",
      "       ... \n",
      "96     2018\n",
      "97     2017\n",
      "98     2017\n",
      "99     2017\n",
      "100    2017\n",
      "Name: acct_year, Length: 101, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Get year of account opened\n",
    "banking['acct_year'] = banking['account_opened'].dt.strftime('%Y')\n",
    "\n",
    "# Print acct_year\n",
    "print(banking['acct_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40a23cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inconsistent investments:  8\n"
     ]
    }
   ],
   "source": [
    "# Motivation\n",
    "# Cross field validation\n",
    "# Store fund columns to sum against\n",
    "# Store fund columns to sum against\n",
    "fund_columns = ['fund_A', 'fund_B', 'fund_C', 'fund_D']\n",
    "\n",
    "# Find rows where fund_columns row sum == inv_amount\n",
    "inv_equ = banking[fund_columns].sum(axis=1) == banking['inv_amount']\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "consistent_inv = banking[inv_equ]\n",
    "inconsistent_inv = banking[~inv_equ]\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "print(\"Number of inconsistent investments: \", inconsistent_inv.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35d3cf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inconsistent ages:  101\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "banking = pd.read_csv('datasets/banking_dirty.csv')\n",
    "\n",
    "# Convert birth_date to datetime\n",
    "banking['birth_date'] = pd.to_datetime(banking['birth_date'],\n",
    "                                           # Infer datetime format\n",
    "                                           infer_datetime_format = True,\n",
    "                                           # Return missing value for error\n",
    "                                           errors = 'coerce') \n",
    "# Store today's date and find ages\n",
    "today = dt.date.today()\n",
    "ages_manual = today.year - banking['birth_date'].dt.year\n",
    "\n",
    "# Find rows where age column == ages_manual\n",
    "age_equ = ages_manual == banking['Age']\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "consistent_ages = banking[age_equ]\n",
    "inconsistent_ages = banking[~age_equ]\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "print(\"Number of inconsistent ages: \", inconsistent_ages.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3e45a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                   int64\n",
       "cust_id                     object\n",
       "birth_date          datetime64[ns]\n",
       "Age                          int64\n",
       "acct_amount                float64\n",
       "inv_amount                   int64\n",
       "fund_A                     float64\n",
       "fund_B                     float64\n",
       "fund_C                     float64\n",
       "fund_D                     float64\n",
       "account_opened              object\n",
       "last_transaction            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banking.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58fdb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completeness\n",
    "# Mising data problem\n",
    "# NA, NaN ( Not A Number ),0 ,. ,\n",
    "\n",
    "# Method to find missing values\n",
    "# .isna()  True for missing value else False\n",
    "# .isna().sum()\n",
    "\n",
    "# # Package to work on missing value\n",
    "# import missingnon as msno\n",
    "# msno.matrix()\n",
    "\n",
    "# # Missingness types\n",
    "# MCAR Missing Completely at Random: No systematic relationship between a column's missing values and other or own values.\n",
    "# MAR Missing at Random: There is a systematic relationship between a column's missing values and other observed values.\n",
    "# MNAR Missing not at Random: There is a systematic relationship between a column's missing values and unobserved values.\n",
    "\n",
    "# # Solution for missing data\n",
    "# 1. Drop missing data\n",
    "# 2. Impute with statistical measures ( mean,medium,)\n",
    "# .fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b354d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b8995e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'missingno'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15632/3385100880.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmissingno\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmsno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbanking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'datasets/banking_dirty.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'missingno'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "banking = pd.read_csv('datasets/banking_dirty.csv')\n",
    "\n",
    "# Print number of missing values in banking\n",
    "print(banking['inv_amount'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7bc46b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
